{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CharlottePrimiceri/VP_Project/blob/main/depthmap/depthmap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Depth map computation**"
      ],
      "metadata": {
        "id": "gGvrol-4q_Oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference:\n",
        "\"\"\"\n",
        "@article{Ranftl2021,\n",
        "\tauthor    = {Ren\\'{e} Ranftl and Alexey Bochkovskiy and Vladlen Koltun},\n",
        "\ttitle     = {Vision Transformers for Dense Prediction},\n",
        "\tjournal   = {ArXiv preprint},\n",
        "\tyear      = {2021},\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "4ouEAGcWq2wF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm --quiet"
      ],
      "metadata": {
        "id": "Q1esJ1tWqzjg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Y81K0wlDOdFg"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ck0FVi4EOxVg"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agQW-LjCPCpH"
      },
      "outputs": [],
      "source": [
        "model_type = \"DPT_Hybrid\"\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "midas.to(device)\n",
        "midas.eval()\n",
        "\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
        "  transform = midas_transforms.dpt_transform\n",
        "else:\n",
        "    transform = midas_transforms.small_transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAqsO3jbEEoF"
      },
      "outputs": [],
      "source": [
        "input_folder = \"/content/drive/MyDrive/VPPROJECT/cityscapes/leftImg8bit/test\"\n",
        "destination_folder = \"/content/drive/MyDrive/VPPROJECT/cityscapes/depth_images/test\"\n",
        "\n",
        "for city in os.listdir(input_folder):\n",
        "    img_dir = os.path.join(input_folder, city)\n",
        "    new_dir = os.path.join(destination_folder, city)\n",
        "    os.makedirs(new_dir, exist_ok=True)\n",
        "    for imgid in os.listdir(img_dir):\n",
        "        path = os.path.join(img_dir,imgid)\n",
        "        output_path = os.path.join(destination_folder, os.path.relpath(path, input_folder))\n",
        "        output_dir = os.path.dirname(output_path)\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        img = cv2.imread(path)\n",
        "        input_batch = transform(img).to(device)\n",
        "        with torch.no_grad():\n",
        "             prediction = midas(input_batch)\n",
        "             prediction = torch.nn.functional.interpolate(\n",
        "             prediction.unsqueeze(1),\n",
        "             size=img.shape[:2],\n",
        "             mode=\"bicubic\",\n",
        "             align_corners=False,\n",
        "             ).squeeze()\n",
        "        depth = prediction.cpu().numpy()\n",
        "        normalized_depth = (depth - np.min(depth)) / (np.max(depth) - np.min(depth))\n",
        "        depth_rgb = cv2.applyColorMap((normalized_depth * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
        "        cv2.imwrite(output_path, depth_rgb)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CharlottePrimiceri/VP_Project/blob/main/Segmented_video_Mask_RCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Segmented video generation applying the pre-trained Mask-RCNN.**\n",
        "\n",
        "THIS SCRIPT TAKES A VIDEO IN INPUT FROM CITYSCAPES AND ELABORATES ALL ITS FRAMES WITH OUR PYTORCH UNET RIVISITED. THEN, THE OPTICAL FLOW VALUE IS COMPUTED ON THE SEGMNETED IMAGES, WITH THE AIM OF ESTIMATING THE SPEED OF OBJECTS IN THE VIDEO.\n",
        "\n",
        "References:\n",
        "\n",
        "- Mask-RCNN:\n",
        "https://github.com/facebookresearch/detectron2.git@5aeb252b194b93dc2879b4ac34bc51a31b5aee13'\n",
        "- Video taken from: https://www.cityscapes-dataset.com/"
      ],
      "metadata": {
        "id": "rRARDshbAGqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install detectron2, import libraries, connect to google drive, set device."
      ],
      "metadata": {
        "id": "9dOR3H6C_x-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch --quiet"
      ],
      "metadata": {
        "id": "0Sa0HJZCCazs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision --quiet"
      ],
      "metadata": {
        "id": "iys5vRhCCXAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install scikit-image --quiet"
      ],
      "metadata": {
        "id": "MmRf4zpuCl1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install opencv-python --quiet"
      ],
      "metadata": {
        "id": "WW6CMTtrCoHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install Pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ri9NL6pC5kc",
        "outputId": "68fd4608-4460-40ff-ec9c-5816e8055ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4lfLXNu_m-G",
        "outputId": "72ee7882-6d73-4e55-a9bc-b188ccdabaaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "#######\n",
        "import scipy\n",
        "import skimage\n",
        "import PIL\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from google.colab.patches import cv2_imshow\n",
        "########\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git@5aeb252b194b93dc2879b4ac34bc51a31b5aee13' --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1JJ1paoBzIr",
        "outputId": "4d04cbd8-ab57-46fa-f27e-be1d38edb535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import detectron2\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.structures import BoxMode"
      ],
      "metadata": {
        "id": "H3BsMVsmB814"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detectron2 configuration"
      ],
      "metadata": {
        "id": "HKicnU8HCFj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = get_cfg()\n",
        "cfg.MODEL.DEVICE = \"cpu\"\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "metadata": {
        "id": "eF62FXATGE8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = \"/content/drive/MyDrive/VPPROJECT/EUREKA/video_making/demoVideo/stuttgart_02/\" # immagini non segmentate\n",
        "segmented_video_path = \"/content/drive/MyDrive/VPPROJECT/EUREKA/video_making/demoVideo/segmented_video/\" # immagini segmentate\n",
        "optical_flow_path = \"/content/drive/MyDrive/VPPROJECT/EUREKA/video_making/demoVideo/opt_flow_for_video/\" # immagini su cui Ã¨ stato applicato opt_flow\n",
        "built_video_path = \"/content/drive/MyDrive/VPPROJECT/EUREKA/video_making/demoVideo/built_video/\"\n",
        "\n",
        "\n",
        "\n",
        "def generate_video(img_folder, video_name, out_path):\n",
        "\n",
        "    images = [img for img in os.listdir(img_folder)]\n",
        "    frame = cv2.imread(os.path.join(img_folder, images[0]))\n",
        "    height, width, layers = frame.shape\n",
        "\n",
        "    os.chdir(out_path)\n",
        "\n",
        "    video = cv2.VideoWriter(video_name, 0, 1, (width, height))   # try 2,3,4 al posto di 1 per velocizzare\n",
        "\n",
        "    for image in images:\n",
        "        video.write(cv2.imread(os.path.join(img_folder, image)))\n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "    video.release()\n",
        "\n",
        "\n",
        "i = 0\n",
        "for image in os.listdir(video_path):\n",
        "    i = i+1\n",
        "    if i % 5 == 0:\n",
        "        image_path = os.path.join(video_path, image)\n",
        "        im = cv2.imread(image_path)\n",
        "\n",
        "        # here we segment the image with the pre-trained Mask-RCNN\n",
        "        pred = predictor(im)\n",
        "        v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "        out = v.draw_instance_predictions(pred[\"instances\"].to(\"cpu\"))\n",
        "        path = os.path.join(segmented_video_path, image)\n",
        "        cv2.imwrite(path, out.get_image()[:, :, ::-1])\n",
        "\n",
        "        # here we compute the optical flow ############# TO DOOOO\n",
        "\n",
        "# Build video from folder segmented_video\n",
        "generate_video(segmented_video_path, \"segmented_video_1.avi\", built_video_path)\n"
      ],
      "metadata": {
        "id": "2JRYx6RIdLw6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}